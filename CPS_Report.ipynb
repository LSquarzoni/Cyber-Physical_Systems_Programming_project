{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook requires Ubuntu 22.04 LTS (Jammy Jellyfish) to be executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary installations with ROS 2 Humble/Ubuntu 22.04 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.ros.org/en/humble/Tutorials.html\n",
    "\n",
    "https://docs.ros.org/en/humble/Installation/Ubuntu-Install-Debians.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install software-properties-common\n",
    "!sudo add-apt-repository universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg\n",
    "!echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release && echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROS installation\n",
    "!sudo apt update\n",
    "!sudo apt upgrade\n",
    "!sudo apt install ros-humble-desktop\n",
    "\n",
    "!sudo apt install ros-dev-tools\n",
    "\n",
    "# Gazebo installation\n",
    "!sudo apt install libgazebo-dev\n",
    "!sudo apt install ros-humble-gazebo-ros-pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS REMEMBER TO SOURCE THIS FILE (or add it in the .bashrc)\n",
    "!source /opt/ros/humble/setup.bash\n",
    "\n",
    "!echo \"source /opt/ros/humble/setup.bash\" >> ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.px4.io/main/en/dev_setup/dev_env_linux_ubuntu.html#ros-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download PX4\n",
    "!git clone https://github.com/PX4/PX4-Autopilot.git --recursive\n",
    "\n",
    "# install\n",
    "!bash ./PX4-Autopilot/Tools/setup/ubuntu.sh -no-sim-tools --no-nuttx\n",
    "\n",
    "# then restart computer\n",
    "\n",
    "# additional dependencies\n",
    "!sudo apt-get install protobuf-compiler libeigen3-dev libopencv-dev -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .SDF to .URDF conversion of the iris model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Rviz requires the drone's model to be in .urdf format, it is mandatory to convert the .sdf file of it to be readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic PX4 Gazebo simulation with IRIS drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd PX4-Autopilot\n",
    "!make px4_sitl gazebo-classic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PX4 Gazebo simulation with IRIS depth camera .urdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd PX4_Autopilot\n",
    "!make px4_sitl gazebo_iris_depth_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROS2 PX4 Offboard script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ARK-Electronics/ROS2_PX4_Offboard_Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro XRCE installation\n",
    "!pip3 install --user -U empy pyros-genmsg setuptools\n",
    "!pip3 install kconfiglib\n",
    "!pip install --user jsonschema\n",
    "!pip install --user jinja2\n",
    "\n",
    "!git clone https://github.com/eProsima/Micro-XRCE-DDS-Agent.git\n",
    "!cd Micro-XRCE-DDS-Agent\n",
    "!mkdir build\n",
    "!cd build\n",
    "!cmake ..\n",
    "!make\n",
    "!sudo make install\n",
    "!sudo ldconfig /usr/local/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside the /ROS2_ws/src directory\n",
    "!git clone https://github.com/PX4/px4_msgs.git\n",
    "!git clone https://github.com/ARK-Electronics/ROS2_PX4_Offboard_Example.git\n",
    "\n",
    "!cd ..\n",
    "!pip install --user -U empy==3.3.4 pyros-genmsg setuptools\n",
    "!colcon build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a different IRIS model file, as our .urdf one, we need to change some lines in ROS2_ws/src/ROS2_PX4_Offboard_Example/px4_offboard/px4_offboard/processes.py:\n",
    "\n",
    " Run the PX4 SITL simulation \n",
    "\n",
    "  \"cd ~/PX4-Autopilot && make px4_sitl gz_x500\"\n",
    "\n",
    "to:\n",
    "\n",
    " Run the PX4 SITL simulation \n",
    " \n",
    "  \"cd ~/PX4-Autopilot && make px4_sitl gazebo-classic_iris_depth_camera__warehouse\" for the warehouse world\n",
    "  \"cd ~/PX4-Autopilot && make px4_sitl gazebo-classic_iris_depth_camera__our_empty\" for our simple world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source the code every time -> from /ROS2_ws\n",
    "!source . install/setup.bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation will be launched with all the required processes, to add new topics or nodes it will be easier to add the corresponding commands directly in the .launch file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the simulation\n",
    "!ros2 launch px4_offboard offboard_velocity_control.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are able to launch Gazebo and Rviz2 with a depth camera equipped drone, publishing the image of it and the associated point cloud that will be used to map the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project we faced a problem with the ROS topic correct publishing, where the data related to the sensor wasn't correctly linked to the map frame, leading to an incompatibility between the sensor itself and the octomap library. To solve this issue we needed to manually publish the topics and link it to the map frame, with the correct transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base_Link and Map publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In /ROS2_ws, when the simulation in gazebo and rviz is running\n",
    "!source . install/setup.bash\n",
    "!ros2 run map_base_link_publ map_base_link_publ\n",
    "!ros2 run map_frame_publisher map_frame_publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PointCloud publishing wrt Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we need to execute one last script in order to transform the pointcloud with respect to the map frame and use it for the mapping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In /ROS2_ws\n",
    "!source . install/setup.bash\n",
    "!ros2 run pointcloud_transformer pointcloud_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease, all these three executions will be added to the launch file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OctoMap Mapping\n",
    "\n",
    "Version for ROS 2 Humble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install ros-humble-octomap-mapping\n",
    "\n",
    "!sudo nautilus # to modify the launch file as needed\n",
    "# The data will then be located at /opt/ros/humble/share/octomap_server/launch/ --> insert the topic /pointcloud_wrt_map and the frame_id as map\n",
    "\n",
    "!ros2 launch octomap_server octomap_mapping.launch.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiagent simulation with PX4 in Gazebo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.px4.io/v1.12/en/simulation/multi_vehicle_simulation_gazebo.html\n",
    "\n",
    "https://microsoft.github.io/AirSim/px4_multi_vehicle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd PX4-Autopilot\n",
    "# !Tools/sitl_multiple_run.sh -m iris -n 2 #-m: name of the model, -n: number of entities, -w: world\n",
    "\n",
    "# !MicroXRCEAgent udp4 -p 8888\n",
    "# # Once we run MicroXRCE we can see the topics of each drone instance referenced as /px4 1, /px4 2, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the **multivehicle simulation files** folder take the files and place (replace the already exisiting files if present) them in the following folders:\n",
    "- *sitl_multiple_run.sh* --> ~/PX4-Autopilot/Tools/simulation/gazebo-classic\n",
    "- *jinja_gen.py* --> ~/PX4-Autopilot/Tools/simulation/gazebo-classic/sitl_gazebo-classic\n",
    "- *iris_depth_camera.sdf.jinja* --> ~/PX4-Autopilot/Tools/simulation/gazebo-classic/sitl_gazebo-classic/models/iris_depth_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the **world** folder take the file and place it in ~/PX4-Autopilot/Tools/simulation/gazebo-classic/sitl_gazebo-classic/worlds. After that, go to ~PX4-Autopilot/src/modules/simulation/simulator_mavlink and open **sitl_targets_gazebo-classic.cmake** and write 'our_empty' among the names all other already existing worlds (from line 110 to 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the *launch* directory in the *px4_offboard* package folder open the launch file. At line 15 replace *drone_ws* with the name of your ROS2 worksapce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IF YOU WANT (NOT NECESSARY TO MAKE THE SIMULATION WORK)** \n",
    "\n",
    "Take the **meshes** folder from the *px4_offboard* package and place it in ~/NAME_OF_YOUR_WORKSPACE/install/px4_offboard/share/px4_offboard. This allows to see the drone's model in Rviz but the simulation works fine anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO RUN THE SIMULATION** from terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/NAME_OF_YOUR_WORKSPACE\n",
    "!colcon build #if you need to compile\n",
    "!source ./install/setup.bash\n",
    "!ros2 launch px4_offboard offboard_velocity_control.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gazebo simulation is launched by the python script *precesses.py* at ~/NAME_OF_YOUR_WORKSPACE/src/px4_offboard/px4_offboard with the command:\n",
    "\n",
    "cd ~/PX4-Autopilot/Tools/simulation/gazebo-classic && ./sitl_multiple_run.sh -s iris_depth_camera:1:0:0,iris_depth_camera:1:3:3 -w our_empty\n",
    "\n",
    "The syntax is --> ./sitl_multiple_run.sh -s MODEL1:N° OF ENTITES:X_COORD:Y_COORD,MODEL2:N° OF ENTITES:X_COORD:Y_COORD, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BRIEF EXPLAINATION OF HOW ALL THIS WORKS**\n",
    "\n",
    "In Gazebo/ROS when multiple entities exist, they must have different frames, topics ecc ecc names. For other models (like *iris*) everything is already managed by PX4 & Co (to each entity is assigned a namespace px4_1, px4_2 ecc,  so each topic name will start with /px4_N/...), but not for the *iris_depth_camera* model.\n",
    "\n",
    "When the *sitl_multiple_run.sh* file is executed it calls the *jinja_gen.py* script that uses the *.sdf.jinja* file of the desired model to generate all the sdf files for all the entities: the sdf.jinja file is like a generic sdf file where the things that must be different among the entities to avoid conflicts are not assigned to a fixed value or have fixed names, but these values/names are received from the sitl_multiple_run.sh and jinja_gen.py files.\n",
    "\n",
    "The sdf.jinja file for the iris_depth_camera model didn't exist, so i created one where I said that the base_link and camera_link frames and something more in the camera_plugin have names taken as parameters from the two scripts. In this way for example the first drone will have *base_link_1* and *camera_link_1* and the second one will have *base_link_2* and *camera_link_2* as frames names.\n",
    "\n",
    "I also created two .urdf files with matching frames names to publish all the frames using the robot_state_publisher nodes.\n",
    "\n",
    "With all this we are able to se the cameras data from all the drones and to create the topics refered to the map frame (pointcloud_wrt_map) to create the Octomap!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEMS**\n",
    "\n",
    "In the single vehicle simulation the map->base_link transform was published starting form the data taken from the topic /fmu/out/vehicle_odometry but with 2 drones this doesn't work: the odometry corresponds to the relative position and orientation of the drone from its initial position and orientation, so if the drone doesn't move the odometry will be always 0 0 0 ... With two drones, both will have odometries equal to 0 0 0 if they don't move, so if we publish the transform map->base_link_1 and map->base_link_2 using the odometry the frames of the two drones will overlap. I tried using other topics like *local_position* but the result is the same. So we need the absolute position of the drones with respect to the world.\n",
    "\n",
    "**POSSIBLE SOLUTIONS**\n",
    "\n",
    "- NOT OPTIMAL BECAUSE COULD WORK ONLY IN SIMULATION, BUT **IN THEORY** EASY: in the *processes.py* instead of writing directly the coordinates of the drones, we can pass them as parameters from the *offboard_velocity_control.launch.py*, so that we can give them as parameters also to the *map_base_link_publisher* node and use them to adjust what we receive for the odometry topic\n",
    "- BETTER BECAUSE IT SHOULD WORK ALSO WITH REAL DRONES, BUT MORE DIFFICULT: implement (or find somewhere) a localization algorithm that can compute the absolute position of each drone using sensors readings. Something already exists but i dont' know if it works with 3D sensor like depth camera and for drones in general\n",
    "- I DON'T KNOW IF IT IS POSSIBLE: there is a topic called vechicle_global_position already provided by PX4 that gives latitude, longitude and altitude of the drone using the GPS and other things. I don't know if there is a way to convert those data into x,y and z coordinates of the drone"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
